# Session: *AI Safety und KI-Ethik – Von Bertha Benz bis SAP Responsible AI*

## Kontext
- Vortrag von **Laugwitz** zum Thema **AI Safety / KI-Ethik**.  
- Fokus: Wie lässt sich KI so gestalten, dass sie keinen Schaden anrichtet?  
- Praxisbezug: Erfahrungen aus SAP und europäische Richtlinien zu vertrauenswürdiger KI.  

## Zentrale Themen
- **Begriffsabgrenzung:**  
  - *Security* = sicher gebaut, *Safety* = sicher in der Anwendung.  
  - Ziel: Schaden vermeiden (für Menschen, Umwelt, Gesellschaft).  
- **Drei Grundpfeiler vertrauenswürdiger KI (EU Guidelines 2018):**  
  - Rechtmäßig  
  - Robust  
  - Ethisch  
- **Historische Analogie:**  
  - Vergleich zur Einführung des Automobils (Bertha Benz 1888).  
  - Technologische Disruption und notwendige Regelungen.  
- **Probleme heutiger KI:**  
  - Bias in Trainingsdaten (Gender-Stereotype).  
  - Generative KI erzeugt oft „Quatsch“ (fehlendes Weltwissen).  
  - Dynamik lernender Systeme → kontinuierliche Kontrolle nötig.  
- **SAP-Ansatz „Responsible AI“:**  
  - KI-Compliance (Gesetze, Regularien).  
  - KI-Sicherheit (robuste Implementierung).  
  - KI-Ethik (Verantwortung, Werte, Fairness).  
- **Kernanforderungen an KI-Ethik:**  
  - Menschliche Kontrolle („Human in the Loop“).  
  - Fairness & Nichtdiskriminierung.  
  - Transparenz & Erklärbarkeit.  

## Highlights / Zitate
- *„AI Safety heißt: Schaden vermeiden.“*  
- *„Trustworthy AI needs to be rechtmäßig, robust und ethisch.“*  
- *„Übt euch in Wachsamkeit – das Tempo der Entwicklung ist atemberaubend.“*  

## Erkenntnisse
- KI hat disruptives Potenzial, vergleichbar mit der Einführung des Automobils.  
- Sicherheit erfordert Zusammenspiel von Technologie, Gesetzen und ethischen Prinzipien.  
- Unternehmen wie SAP implementieren Policies und Bewertungsprozesse für KI-Ethik.  
- Bewusstsein für Bias, Blackbox-Charakter und Limitationen von KI ist entscheidend.  

## Nächste Schritte / Offene Fragen
- Wie lassen sich Ethik-Standards international harmonisieren?  
- Welche Instrumente sichern Transparenz in komplexen KI-Systemen?  
- Wie kann gesellschaftliche Aufklärung über KI-Risiken breiter verankert werden?  
- Rolle der Unternehmen: Von Selbstverpflichtung zu verbindlichen Standards?  
